{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T11:46:46.484256Z",
     "start_time": "2021-09-01T11:46:46.477302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001C17345AA00>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"Sentiment-Analysis\").getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T11:50:04.587877Z",
     "start_time": "2021-09-01T11:50:04.580001Z"
    }
   },
   "outputs": [],
   "source": [
    "df =  spark.createDataFrame(pd.read_json('climatechange-v2.json'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(':)', 3691), (':-)', 701), (':d', 658), ('thanks', 388), ('follow', 357), ('love', 333), ('...', 290), ('good', 283), ('get', 263), ('thank', 253)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "\n",
    "import re, string, random\n",
    "\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "def get_tweets_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tweet_tokens)\n",
    "\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "positive_tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "negative_tweet_tokens = twitter_samples.tokenized('negative_tweets.json')\n",
    "\n",
    "positive_cleaned_tokens_list = []\n",
    "negative_cleaned_tokens_list = []\n",
    "\n",
    "for tokens in positive_tweet_tokens:\n",
    "    positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "for tokens in negative_tweet_tokens:\n",
    "    negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "\n",
    "freq_dist_pos = FreqDist(all_pos_words)\n",
    "print(freq_dist_pos.most_common(10))\n",
    "\n",
    "positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n",
    "negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n",
    "\n",
    "positive_dataset = [(tweet_dict, \"Positive\")\n",
    "                    for tweet_dict in positive_tokens_for_model]\n",
    "\n",
    "negative_dataset = [(tweet_dict, \"Negative\")\n",
    "                    for tweet_dict in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train_data = dataset[:7000]\n",
    "test_data = dataset[7000:]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c44b3b762903>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mdf_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "analysis=[]\n",
    "for i in range(0,df.count()):\n",
    "    custom_tweet=df.collect()[i][\"text\"]\n",
    "    custom_tokens=remove_noise(word_tokenize(custom_tweet))\n",
    "    analysis.append(classifier.classify(dict([token, True] for token in custom_tokens)))\n",
    "    \n",
    "res = []\n",
    "for i in analysis:\n",
    "    sub = i.split(', ')\n",
    "    res.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Sentiment|\n",
      "+---------+\n",
      "| Positive|\n",
      "| Negative|\n",
      "| Positive|\n",
      "| Positive|\n",
      "| Positive|\n",
      "| Positive|\n",
      "| Positive|\n",
      "| Negative|\n",
      "| Negative|\n",
      "| Positive|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns=[\"Sentiment\"] \n",
    "df_a = spark.createDataFrame(res, columns)\n",
    "df_a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Resolved attribute(s) Sentiment#38 missing from id#0L,username#1,text#2,favourite_count#3L,retweet_count#4L,source#5,location#6 in operator !Project [id#0L, username#1, text#2, favourite_count#3L, retweet_count#4L, source#5, location#6, Sentiment#38 AS Sentiment#60].;\n!Project [id#0L, username#1, text#2, favourite_count#3L, retweet_count#4L, source#5, location#6, Sentiment#38 AS Sentiment#60]\n+- LogicalRDD [id#0L, username#1, text#2, favourite_count#3L, retweet_count#4L, source#5, location#6], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e7ec730f32fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sentiment\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Spark\\spark-3.1.2-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   2453\u001b[0m         \"\"\"\n\u001b[0;32m   2454\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"col should be Column\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2455\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Spark\\spark-3.1.2-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Spark\\spark-3.1.2-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Resolved attribute(s) Sentiment#38 missing from id#0L,username#1,text#2,favourite_count#3L,retweet_count#4L,source#5,location#6 in operator !Project [id#0L, username#1, text#2, favourite_count#3L, retweet_count#4L, source#5, location#6, Sentiment#38 AS Sentiment#60].;\n!Project [id#0L, username#1, text#2, favourite_count#3L, retweet_count#4L, source#5, location#6, Sentiment#38 AS Sentiment#60]\n+- LogicalRDD [id#0L, username#1, text#2, favourite_count#3L, retweet_count#4L, source#5, location#6], false\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Sentiment\",df_a.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.unionByName(df_a, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=merged_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>JFSebastian146</td>\n",
       "      <td>RT @lavergnetho: @AschbacherJosef @IPCC_CH @es...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>My1stNewApp</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>SAFER_Lab</td>\n",
       "      <td>RT @JacobEurich: Accepting abstracts for our O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Rhodes University, RSA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>XylemWater</td>\n",
       "      <td>RT @WaterUK: üåçEveryone can help fight #Climate...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>Lorenz41294196</td>\n",
       "      <td>üëã @SenSchumer @SpeakerPelosi thank you for you...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>_thebastion_</td>\n",
       "      <td>Urgent decisive action at the intersection of ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>PopCounts</td>\n",
       "      <td>RT @PopnMatters: A bit unsure of the links bet...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Global</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>Farozaankhi</td>\n",
       "      <td>RT @UrbanPlannerNED: Glad to see it as #Faroza...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>JFSebastian146</td>\n",
       "      <td>RT @ProfStrachan: Sixty years of #ClimateChang...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>My1stNewApp</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>Stephen31626808</td>\n",
       "      <td>RT @Love_plants: Thread: @IanPlantlife on @bgc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.432970e+18</td>\n",
       "      <td>iamgabbarson</td>\n",
       "      <td>RT @TPD_Journal: Featuring #OpenAccess #Resear...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hey OA</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id         username  \\\n",
       "0   1.432970e+18   JFSebastian146   \n",
       "1   1.432970e+18        SAFER_Lab   \n",
       "2   1.432970e+18       XylemWater   \n",
       "3   1.432970e+18   Lorenz41294196   \n",
       "4   1.432970e+18     _thebastion_   \n",
       "5   1.432970e+18        PopCounts   \n",
       "6   1.432970e+18      Farozaankhi   \n",
       "7   1.432970e+18   JFSebastian146   \n",
       "8   1.432970e+18  Stephen31626808   \n",
       "9   1.432970e+18     iamgabbarson   \n",
       "10           NaN             None   \n",
       "11           NaN             None   \n",
       "12           NaN             None   \n",
       "13           NaN             None   \n",
       "14           NaN             None   \n",
       "15           NaN             None   \n",
       "16           NaN             None   \n",
       "17           NaN             None   \n",
       "18           NaN             None   \n",
       "19           NaN             None   \n",
       "\n",
       "                                                 text  favourite_count  \\\n",
       "0   RT @lavergnetho: @AschbacherJosef @IPCC_CH @es...              0.0   \n",
       "1   RT @JacobEurich: Accepting abstracts for our O...              0.0   \n",
       "2   RT @WaterUK: üåçEveryone can help fight #Climate...              0.0   \n",
       "3   üëã @SenSchumer @SpeakerPelosi thank you for you...              0.0   \n",
       "4   Urgent decisive action at the intersection of ...              0.0   \n",
       "5   RT @PopnMatters: A bit unsure of the links bet...              0.0   \n",
       "6   RT @UrbanPlannerNED: Glad to see it as #Faroza...              0.0   \n",
       "7   RT @ProfStrachan: Sixty years of #ClimateChang...              0.0   \n",
       "8   RT @Love_plants: Thread: @IanPlantlife on @bgc...              0.0   \n",
       "9   RT @TPD_Journal: Featuring #OpenAccess #Resear...              0.0   \n",
       "10                                               None              NaN   \n",
       "11                                               None              NaN   \n",
       "12                                               None              NaN   \n",
       "13                                               None              NaN   \n",
       "14                                               None              NaN   \n",
       "15                                               None              NaN   \n",
       "16                                               None              NaN   \n",
       "17                                               None              NaN   \n",
       "18                                               None              NaN   \n",
       "19                                               None              NaN   \n",
       "\n",
       "    retweet_count               source                location Sentiment  \n",
       "0            10.0          My1stNewApp                              None  \n",
       "1            15.0      Twitter Web App  Rhodes University, RSA      None  \n",
       "2             6.0      Twitter Web App          United Kingdom      None  \n",
       "3             0.0  Twitter for Android                              None  \n",
       "4             0.0      Twitter Web App               New Delhi      None  \n",
       "5             9.0  Twitter for Android                  Global      None  \n",
       "6             2.0      Twitter Web App                 Karachi      None  \n",
       "7           166.0          My1stNewApp                              None  \n",
       "8             4.0      Twitter Web App                              None  \n",
       "9             1.0               Hey OA              New Jersey      None  \n",
       "10            NaN                 None                    None  Positive  \n",
       "11            NaN                 None                    None  Negative  \n",
       "12            NaN                 None                    None  Positive  \n",
       "13            NaN                 None                    None  Positive  \n",
       "14            NaN                 None                    None  Positive  \n",
       "15            NaN                 None                    None  Positive  \n",
       "16            NaN                 None                    None  Positive  \n",
       "17            NaN                 None                    None  Negative  \n",
       "18            NaN                 None                    None  Negative  \n",
       "19            NaN                 None                    None  Positive  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
